{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d16e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'train' to './datasets/coco-2017/train' if necessary\n",
      "Found annotations at 'datasets/coco-2017/raw/instances_train2017.json'\n",
      "Sufficient images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'coco-2017-train-10000'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      "Downloading split 'validation' to './datasets/coco-2017/validation' if necessary\n",
      "Found annotations at 'datasets/coco-2017/raw/instances_val2017.json'\n",
      "Sufficient images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading existing dataset 'coco-2017-validation-2000'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      "Downloading split 'test' to './datasets/coco-2017/test' if necessary\n",
      "Found test info at 'datasets/coco-2017/raw/image_info_test2017.json'\n",
      "1522 images found; downloading the remaining 478\n",
      " 100% |██████████████████| 478/478 [23.2s elapsed, 0s remaining, 21.2 images/s]      \n",
      "Writing annotations for 2000 downloaded samples to './datasets/coco-2017/test/labels.json'\n",
      "Dataset info written to './datasets/coco-2017/info.json'\n",
      "Loading 'coco-2017' split 'test'\n",
      " 100% |███████████████| 2000/2000 [259.9ms elapsed, 0s remaining, 7.7K samples/s]   \n",
      "Dataset 'coco-2017-test-2000' created\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "fo.config.dataset_zoo_dir = \"./datasets\"\n",
    "\n",
    "# Download and load the validation split of COCO-2017\n",
    "train_ds = foz.load_zoo_dataset(\"coco-2017\", split=\"train\", max_samples=10000, shuffle=True, seed=42)\n",
    "val_ds   = foz.load_zoo_dataset(\"coco-2017\", split=\"validation\", max_samples=2000, shuffle=False)\n",
    "test_ds  = foz.load_zoo_dataset(\"coco-2017\", split=\"test\", max_samples=2000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b79b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attaching captions to dataset samples, since fiftyone doesn't currently include them\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def add_captions(dataset, captions_file):\n",
    "    #read COCO captions file\n",
    "    with open(captions_file) as f:\n",
    "        caps = json.load(f)\n",
    "    \n",
    "    #image_id -> [caption, ...]\n",
    "    caps_by_id = defaultdict(list)\n",
    "    for ann in caps[\"annotations\"]:\n",
    "        caps_by_id[ann[\"image_id\"]].append(ann[\"caption\"])\n",
    "\n",
    "    #file_name -> image_id\n",
    "    id_by_fname = {img[\"file_name\"]: img[\"id\"] for img in caps[\"images\"]}\n",
    "\n",
    "    for sample in dataset:\n",
    "        fname = sample.filepath.split(\"/\")[-1]\n",
    "        coco_id = id_by_fname.get(fname)\n",
    "        if coco_id is not None:\n",
    "            sample[\"captions\"] = caps_by_id.get(coco_id, [])\n",
    "            sample.save()\n",
    "\n",
    "add_captions(train_ds, \"datasets/coco-2017/raw/captions_train2017.json\")\n",
    "add_captions(val_ds, \"datasets/coco-2017/raw/captions_val2017.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fe5cbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 2000 2000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds), len(val_ds), len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f28b2118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wxy/Desktop/Dev/DL/image caption/datasets/coco-2017/validation/data/000000007386.jpg\n",
      "<Detections: {\n",
      "    'detections': [\n",
      "        <Detection: {\n",
      "            'id': '6920275b7e816a9715b281c3',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'dog',\n",
      "            'bounding_box': [0.30151666666666666, 0.70285, 0.064, 0.1137],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'animal',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '6920275b7e816a9715b281c4',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'motorcycle',\n",
      "            'bounding_box': [0.0852, 0.031400000000000004, 0.9148, 0.9686],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'vehicle',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '6920275b7e816a9715b281c5',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'bicycle',\n",
      "            'bounding_box': [\n",
      "                0.36974999999999997,\n",
      "                0.252425,\n",
      "                0.11336666666666666,\n",
      "                0.163075,\n",
      "            ],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'vehicle',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '6920275b7e816a9715b281c6',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'bicycle',\n",
      "            'bounding_box': [0.36446666666666666, 0.39695, 0.10175, 0.13835],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'vehicle',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '6920275b7e816a9715b281c7',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'truck',\n",
      "            'bounding_box': [0.6643833333333333, 0.3619, 0.20171666666666666, 0.2257],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'vehicle',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "    ],\n",
      "}>\n",
      "['a small motor bike outside of the garage', 'A tricycle sits outside of a garage. ', 'A motorcycle parked in front of an open garage.', 'a home made three wheeled trike sitting in a driveway', 'A motorcycle frame that has been made in to a tricycle. ']\n",
      "\n",
      "/Users/wxy/Desktop/Dev/DL/image caption/datasets/coco-2017/validation/data/000000182202.jpg\n",
      "<Detections: {\n",
      "    'detections': [\n",
      "        <Detection: {\n",
      "            'id': '6920275e7e816a9715b2b362',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'cell phone',\n",
      "            'bounding_box': [\n",
      "                0.090578125,\n",
      "                0.2674285714285714,\n",
      "                0.429875,\n",
      "                0.6067272727272728,\n",
      "            ],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'electronic',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '6920275e7e816a9715b2b363',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'laptop',\n",
      "            'bounding_box': [0.24253125, 0.0, 0.75625, 0.8158701298701299],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'electronic',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '6920275e7e816a9715b2b364',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'keyboard',\n",
      "            'bounding_box': [\n",
      "                0.377484375,\n",
      "                0.0017142857142857144,\n",
      "                0.622515625,\n",
      "                0.23654545454545453,\n",
      "            ],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'electronic',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '6920275e7e816a9715b2b365',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'dining table',\n",
      "            'bounding_box': [0.0, 0.07272727272727272, 1.0, 0.9116883116883117],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'furniture',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "    ],\n",
      "}>\n",
      "['An open laptop computer sitting next to a  phone.', 'A cellphone next to a laptop computer. ', 'A vodafone sitting on a table next to a Mac laptop.', 'A Vodafone cell phone sitting next to a laptop.', 'A flip phone sitting next to a laptop computer.']\n",
      "\n",
      "/Users/wxy/Desktop/Dev/DL/image caption/datasets/coco-2017/validation/data/000000012667.jpg\n",
      "<Detections: {\n",
      "    'detections': [\n",
      "        <Detection: {\n",
      "            'id': '6920275c7e816a9715b28338',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'banana',\n",
      "            'bounding_box': [\n",
      "                0.44349999999999995,\n",
      "                0.10154166666666667,\n",
      "                0.25589062500000004,\n",
      "                0.5026875,\n",
      "            ],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'food',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "    ],\n",
      "}>\n",
      "['The telephone has a banana where the receiver should be.', 'A banana replacing the phone on an answering machine', 'A phone with a banana where the receiver should be.', 'A telephone has it receiver replaced with a banana.', 'A banana placed on a phone on a table.']\n",
      "\n",
      "/Users/wxy/Desktop/Dev/DL/image caption/datasets/coco-2017/validation/data/000000061171.jpg\n",
      "<Detections: {\n",
      "    'detections': [\n",
      "        <Detection: {\n",
      "            'id': '6920275c7e816a9715b290c5',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'horse',\n",
      "            'bounding_box': [\n",
      "                0.0016250000000000001,\n",
      "                0.1765625,\n",
      "                0.43735937500000005,\n",
      "                0.6781874999999999,\n",
      "            ],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'animal',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '6920275c7e816a9715b290c6',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'cow',\n",
      "            'bounding_box': [\n",
      "                0.522875,\n",
      "                0.03333333333333333,\n",
      "                0.47471874999999997,\n",
      "                0.5798749999999999,\n",
      "            ],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'animal',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '6920275c7e816a9715b290c7',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'cow',\n",
      "            'bounding_box': [\n",
      "                0.501625,\n",
      "                0.0033750000000000004,\n",
      "                0.23535937499999998,\n",
      "                0.3814791666666667,\n",
      "            ],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'animal',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '6920275c7e816a9715b290c8',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'cow',\n",
      "            'bounding_box': [\n",
      "                0.4329375,\n",
      "                0.0011250000000000001,\n",
      "                0.131109375,\n",
      "                0.17683333333333331,\n",
      "            ],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'animal',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '6920275c7e816a9715b290c9',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'cow',\n",
      "            'bounding_box': [\n",
      "                0.5827656250000001,\n",
      "                0.01914583333333333,\n",
      "                0.40203125,\n",
      "                0.28379166666666666,\n",
      "            ],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'animal',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '6920275c7e816a9715b290ca',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'cow',\n",
      "            'bounding_box': [\n",
      "                0.6896093750000001,\n",
      "                0.28052083333333333,\n",
      "                0.31039062500000003,\n",
      "                0.6805208333333332,\n",
      "            ],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'animal',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '6920275c7e816a9715b290cb',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'cow',\n",
      "            'bounding_box': [0.18896875, 0.0051875, 0.321421875, 0.44416666666666665],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'animal',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "    ],\n",
      "}>\n",
      "['A herd of black and white cows eating dry grass.', 'Several cows and a horse are eating hay.', 'Cows and ponies are eating hay in the barn', 'The animals are grazing on the wheat grain', 'A horse and several cows feed on hay.']\n",
      "\n",
      "/Users/wxy/Desktop/Dev/DL/image caption/datasets/coco-2017/validation/data/000000178618.jpg\n",
      "<Detections: {\n",
      "    'detections': [\n",
      "        <Detection: {\n",
      "            'id': '6920275e7e816a9715b2b1ba',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'elephant',\n",
      "            'bounding_box': [\n",
      "                0.526457399103139,\n",
      "                0.372953125,\n",
      "                0.39991031390134535,\n",
      "                0.29375,\n",
      "            ],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'animal',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '6920275e7e816a9715b2b1bb',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'elephant',\n",
      "            'bounding_box': [\n",
      "                0.0,\n",
      "                0.42774999999999996,\n",
      "                0.05838565022421525,\n",
      "                0.14520312500000002,\n",
      "            ],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'animal',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "        <Detection: {\n",
      "            'id': '6920275e7e816a9715b2b1bc',\n",
      "            'attributes': {},\n",
      "            'tags': [],\n",
      "            'label': 'elephant',\n",
      "            'bounding_box': [\n",
      "                0.4682062780269058,\n",
      "                0.44706250000000003,\n",
      "                0.0682286995515695,\n",
      "                0.05184375,\n",
      "            ],\n",
      "            'mask': None,\n",
      "            'mask_path': None,\n",
      "            'confidence': None,\n",
      "            'index': None,\n",
      "            'supercategory': 'animal',\n",
      "            'iscrowd': 0,\n",
      "        }>,\n",
      "    ],\n",
      "}>\n",
      "['A dust cloud has formed in front of an elephant.', 'An elephant standing in a dust filled field.', 'an elephant is standing in a dirt field', 'An elephant is standing in a dusty dry field.', 'A large brown elephant standing on the dirt ground.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view sample data\n",
    "for sample in val_ds.take(5):\n",
    "    print(sample.filepath)\n",
    "    print(sample.ground_truth) #object label and bounding boxes\n",
    "    print(sample.captions) #captions\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
